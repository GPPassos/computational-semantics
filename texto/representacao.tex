%Hole Semantics: Semântica de Vãos? Semântica de Buracos? Semântica de Lacunas?

\subsection{Introdução}

Desejamos associar a cada expressão de linguagem natural um significado formal, simbólico. Além disso, desejamos fazê-lo de modo algorítmico, que possa ser reproduzido por um computador.
\todo{Conferir se falo de lógica aqui ou se puxo isso para a introdução.}

A linguagem formal que utilizaremos para representar o significado de frases é \textit{lógica de primeira ordem}. \citet{Jurafsky:2009} apresentam como propriedades interessantes para representações: verificabilidade, representações não ambíguas, existência de uma forma canônica, capacidade de inferência e uso de variáveis e expressividade. Todas estas são possuídas pela lógica de primeira ordem. %todo: discutir essas propriedades?
Também uma interessante propriedade da lógica de primeira ordem é sua relativa intuitividade. Bastando explicar o que significam os símbolos conectivos (como $\land$ (significando \expr{e}) e $\rightarrow$ (significando \expr{se \dots então \dots})), bem como os quantificadores ($\forall$ (\expr{para todo})  e $\exists$ (\expr{existe}), uma expressão formal em lógica é compreensível . \todo{é verdade?}

Ainda que tenhamos escolhido a lógica de primeira ordem para ser a linguagem das representações semânticas para frases, isto não nos informa qual deve ser a representação semântica de palavras e expressões menores. Talvez algumas poderiam ser feitas por termos, mas não está de todo claro qual seria o significado de uma expressão como \expreng{to run} (\expr{correr}) ou \expreng{that walks} (\expr{que anda}).

Em nossos pressupostos, adotamos o \textit{Princípio da Composicionalidade}. Segundo o mesmo, o significado de expressões complexas é função das expressões mais simples que a compõem. Em um exemplo como \expreng{Caim kills Abel}, isto nos informa que o significado desta frase depende do significado de \expreng{Caim}, \expreng{kills} e \expreng{Abel}. Entretanto, isto não nos diz como funciona esta dependência, ou a função que leva o significado das expressões simples ao da expressão complexa.

Por exemplo, podemos entender que o significado de \expreng{kills} é o predicado binário \code{kill(\dots , \dots)}, onde convencionamos que o primeiro argumento é o agressor (isto é, aquele que mata) e o segundo argumento é a vítima (aquele que é morto). Também podemos entender os significados de \expreng{Caim} e \expreng{Abel} como as constantes \code{caim} e \code{abel}, respectivamente. Assim, apesar de \code{kill(abel,caim} ser formada com o significado destes três termos, respeitando a composicionalidade, esta não é a expressão que queremos, e sim \code{kill(caim,abel)}.

O que nos falta é a \textit{sintaxe}. A sintaxe é o conjunto de regras e processos que organizam a estrutura de frases. \todo[inline]{achar uma boa referência} Assim, as palavras em uma frase existem em relação a uma certa estrutura, que é essencial para capturar o significado. No inglês, com a estrutura \textit{Sujeito - Verbo - Predicado}, entendemos que \expreng{Caim kills Abel} significa \code{kill(caim,abel)}, e não \code{kill(abel,caim)}.

O foco deste trabalho não é na sintaxe, de modo que utilizamos uma sintaxe simples: a gramática é implementada pelo mecanismo de Gramática de Cláusulas Definidas (\textit{Definite Clause Grammar} - DCG). A análise sintática é feita na forma de uma árvore cujos nós que são folhas são categorias sintáticas básicas (tais como sujeito (\teng{noun}), verbo transitivo (\teng{transitive verb}) e quantificador (\teng{quantifier}, considerado caso particular de \teng{determiner}). Já os nós que não são folhas representam categorias sintáticas complexas (tais como sintagma nominal (\teng{noun phrase}) ou sintagma verbal (\teng{verb phrase}). \cite[p.~58]{BlackburnBos:2005} %Fossem apenas as classes gramaticais, seria uma Gramática Livre de Contexto. Porém, a Gramática de Cláusulas Definidas aceita o uso de algumas restrições, indo além de tal formalismo,como restrições de concordância de número. %Talvez mesmo assim seja possível converter em uma Context Free Grammar (CFG).

Um exemplo de tal árvore, para a frase \expreng{\teng{Caim kills Abel}}, seria:

\Tree [.{\teng{Caim kills Abel} (\teng{Sentence}) } 
[.{\teng{Caim} (\teng{NP})} {\teng{Caim} (\teng{PN})} ]
[.{\teng{kills Abel} (\teng{VP})}
{\teng{kills} (\teng{TV})} [.{\teng{Abel} (\teng{NP})} {\teng{Abel} (\teng{PN})} ] ]
] \\

Aqui, temos as classes sintáticas:\\
\teng{NP} -- \teng{noun phrase} (sintagma nominal)\\
\teng{PN} -- \teng{proper noun} (nome próprio)\\
\teng{VP} -- \teng{verb phrase} (sintagma verbal)\\
\teng{TV} -- \teng{transitive verb} (verbo transitivo)

A decomposição parece lingüisticamente razoável, bem como útil para a compreensão do significado. Resta saber, assim, como podemos elaborar a construção da semântica de uma frase completa a partir de tal análise sintática e dos significados dos termos mais elementares. Essa idéia nos seguirá pelo restante do trabalho, permitindo separar nossas análises, bem como nossos códigos, pela seguinte idéia: a sintaxe da nossa linguagem natural objeto pode ser separada em léxico, a análise de palavras ou expressões em si, como unidades básicas; e em gramática, a análise de como as classes sintáticas se compõem para formar novas, bem como outras relações de concordância (como concordância de gênero ou de número). Já a semântica também pode ser tratada a nível de léxico, em que cada classe sintática básica terá um modelo próprio de interpretação semântica; bem como a nível de gramática, em que a semântica de uma expressão complexa será formada por uma forma de composição entre as semânticas das expressões que a constituem.

\subsection{Cálculo Lambda}

Para realizar um método sistemático de composição dos significados, é introduzido o formalismo do \textit{cálculo lambda}. Aqui, ele será uma extensão da linguagem da lógica de primeira ordem. Dois símbolos novos serão introduzidos: o símbolo de abstração \expr{$\lambda$} e o de aplicação \expr{$@$}.

O símbolo \expr{$\lambda$} será um operador sobre variáveis, permitindo a ``captura'' das mesmas, do mesmo modo a que um quantificador (como \expr{$\forall$}). Por exemplo, sendo \code{man(x)} uma fórmula de primeira ordem, \code{\lambda x.man(x)} é uma fórmula do nosso cálculo lambda, em que a variável $x$ está capturada pelo operador $\lambda$; alternativamente, $\lambda x.$ está \textsl{abstraindo sobre} $x$. 

Por sua vez, o símbolo \expr{$@$}, que conecta duas fórmulas de cálculo lambda, representa uma \textit{aplicação}. Assim, se $F$ e $A$ são duas fórmulas de cálculo lambda, $F@A$ é também uma fórmula de cálculo lambda, chamada uma \textit{aplicação funcional} de $F$ em $A$, ou uma aplicação na qual $F$ é um \textsl{funtor} e $A$ é o \textsl{argumento}. Por exemplo, em \code{\lambda x. man(x)@john}, o funtor é \code{\lambda x. man(x)} e o argumento é \code{john}.

Uma expressão de aplicação funcional representa o comando de aplicar o argumento no funtor, que usualmente será prefixado por uma abstração. A interpretação desse comando é: retire o prefixo de abstração do funtor e, em toda ocorrência da variável abstraída, a substitua pelo argumento da aplicação. Por exemplo, em \code{\lambda x. man(x)@john}, o funtor é \code{\lambda x. man(x)} e a interpretação do comando é de retirar o prefixo \code{\lambda x.} e substituir toda ocorrência de \code{x} no funtor pelo argumento \code{john}, o que produz o resultado de \code{man(john)}. Transformar uma aplicação em sua fórmula resultante após o processo de aplicação é uma operação chamada de \textit{$\beta$-redução}, \textit{$\beta$-conversão} ou \textit{$\lambda$-conversão}. \cite[p.~67]{BlackburnBos:2005}

Destacamos que aplicações podem ser subfórmulas de outras fórmulas, com a $\beta$-redução da fórmula maior sendo a $\beta$-redução de suas subfórmulas, bem como que não é necessário ser um termo ou uma variável para ser um argumento de uma aplicação. Veja este exemplo:
É bem formada a fórmula $(\lambda P. P@mia)@\lambda x.woman(x)$. Em uma primeira etapa de $\beta$-redução, chegamos à fórmula $\lambda x.woman(x)@mia$ e aí, mais uma vez realizando a operação, chegamos à sua $\beta$-redução final $woman(mia)$.

Um cuidado a se ter é que pode ser necessário trocar o símbolo das variáveis em uma aplicação. É suficiente trocar todas as variáveis ligadas (isto é, capturadas por um operador) do funtor por variáveis novas, não utilizadas até então. A operação de substituir todas as variáveis ligadas por outras é chamada de \textit{$\alpha$-conversão}, enquanto se uma fórmula pode ser gerada através de $\alpha$-conversão de outra, as duas fórmulas são ditas \textit{$\alpha$-equivalentes}. Para um exemplo em que não realizar a $\alpha$-conversão antes de uma $\beta$-conversão pode gerar problemas, basta realizar a $\beta$-conversão da seguinte expressão: $\lambda x .\exists y. not\_equal(x,y) @ y$. O resultado incorreto seria $\exists y. not\_equal(y,y)$, enquanto o resultado adequado seria $\exists y. not\_equal(z,y)$.

Desse modo, temos o cálculo lambda como uma ``linguagem de cola'', permitindo fazer composições de expressões até gerar verdadeiras expressões de primeira ordem. A abordagem então é criar, de algum modo, a representação semântica a nível de léxico (isto é, a nível de classes sintáticas básicas), bem como montar a representação semântica a nível da gramática, pela composição de termos mais simples, de algum modo compatível com a semântica a nível lexical. Vejamos alguns exemplos:

Para nomes próprios (\teng{proper names}), a semântica é: \code{\lambda u. u @ symbol}, onde \code{symbol} representa o símbolo do nome próprio (por exemplo, \code{john}).

Por sua vez, para verbos transitivos temos a semântica \code{\lambda k. \lambda y. k@(\lambda x. symbol(y,x))}, onde mais uma vez \code{symbol} reprenta o símbolo específico da palavra (por exemplo, \code{kill}).

Pensemos agora no sintagma verbal (\teng{verb phrase}) \expreng{kills Abel}. Um modo natural de pensar na composição é, sendo $A$ a expressão semântica de \expr{kill} e $B$, a de \expr{Abel}, realizar a aplicação $A@B$. Com efeito, fazendo isso teríamos:
\begin{align*}
&(\lambda k. \lambda y. k@(\lambda x. kill(y,x))) @ \lambda u. u@abel \\
& \lambda y. ((\lambda u. u@abel)@(\lambda x. kill(y,x))) \\
& \lambda y. (\lambda x.kill(y,x)@abel) \\
& \lambda y. kill(y,abel)
\end{align*}

Agora, podemos juntar o sintagma nominal (e também nome próprio) \expreng{Caim} e o sintagma verbal \expreng{kills Abel}, aplicando a semântica do segundo na do primeiro, de onde teríamos:
\begin{align*}
&(\lambda u. u@caim)@(\lambda y.kill(y,abel)) \\
& (\lambda y. kill(y,abel))@caim \\
& kill(caim,abel)
\end{align*}

Assim, chegamos a uma representação da frase \expreng{Caim kills Abel} que é uma expressão de lógica de primeira ordem, utilizando o cálculo lambda como ferramenta para composição sistemática do sentido de expressões menores.

\subsubsection{Dificuldades -- Ambigüidades de Escopo}
Apesar deste método produzir resultados interessantes, ele não é suficiente. Uma característica particular é que, do modo que realizamos, cada decomposição sintática está associada a apenas uma possibilidade semântica. Isto não quer dizer que o modelo até então não consegue tratar de ambigüidades.

Em primeiro lugar, as ambigüidades lexicais podem ser tratadas colocando em nosso sistema todos os sentidos possíveis de determinada expressão. Assim, homógrafos (palavras com a mesma grafia mas significados distintos) podem ser considerados como entradas distintas em nosso banco de dados da semântica lexical. Um uso interessante da linguagem Prolog está no fato de que a mesma possibilita a geração de diversos resultados possíveis, pelo mecanismo de \teng{\textit{backtracking}}. Assim, a implementação em Prolog permite que a semântica a nível léxico seja capturada. Em segundo lugar, ambigüidades por diferentes possibilidades de decomposição sintática de uma mesa frase também podem ser tratadas pelo modelo até então. Novamente, a implementação se beneficia do mecanismo de \teng{\textit{backtracking}} do Prolog, de modo que diferentes decomposições sintáticas e seus significados associados podem ser gerados sucessivamente.

Entretanto, podemos apontar um tipo de ambigüidade que, até então, nosso modelo é incapaz de tratar: as ditas \textit{ambigüidades de escopo}. \cite[p.~105-109]{BlackburnBos:2005} As ambigüidades de escopo são melhor explicadas através de exemplos.

Analisemos a frase: 
\begin{align*}
\text{\expreng{Every man loves a woman.}}
\end{align*}%ocorrem quando há dúvidas a respeito da precedência, ou da ``captura'', de um conteúdo semântico em relação a outros.

Esta frase parece ter duas interpretações possíveis: na primeira, para cada homem existe uma mulher amada por aquele. Possivelmente, são mulheres distintas. Já na segunda leitura, existe uma mulher específica que é amada por todos os homens.

Essa dúvida parece ser gerada pelo \textit{escopo} dos quantificadores \expreng{every} e \expreng{a}. Caso o quantificador \expreng{every} seja \textit{mais externo} (ou \textit{\teng{out-scoping}}) ao quantificador \expreng{a}, então teremos a primeira leitura. Neste caso, também dizemos que o quantificador \expreng{every} tem \textit{escopo sobre} o quantificador \expreng{a}. Por outro lado, caso o quantificador \expreng{a} tenha escopo sobre o quantificador \expreng{every}, a leitura será a segunda. Perceba que, ao que parece, as ambigüidades de escopo não são geradas por, realmente, análises sintáticas distintas, mas sim por uma dificuldade de atribuição de significado à uma decomposição sintática em particular.

Que o nosso sistema atual não é capaz de representar esse tipo de ambigüidade pode ser visto pelo fato de que a representação semântica é única, dados o sentido dos termos mais simples e a decomposição sintática. Precisamos, assim, aprimorar o modelo.

Para termos um olhar em direção à solução, podemos notar que a ocorrência de quantificadores gera seus problemas na função sintática de sintagma nominal (\teng{noun phrase}), pois a combinação quantificador e substantivo (\teng{determiner + noun}) ocorre apenas nela. Isso sugere que alteremos o modo pelo qual tratamos a semântica dos sintagmas nominais com quantificadores.

\subsection{Armazenamento de Cooper}

Para o problema das ambigüidades de escopo, a solução computacional proposta é o uso de \textit{armazenamentos}. Nesta abordagem, a representação semântica de cada expressão deixa de ser a de uma simples fórmula em cálculo lambda, para ser a de uma representação de múltiplas formas possíveis.

Em particular, começaremos com o \textit{armazenamento de Cooper}. Esta é uma técnica desenvolvida por Robin Cooper para lidar com ambigüidades de escopo de quantificadores. \cite[p.~113]{BlackburnBos:2005} Intuitivamente, a idéia está em adicionar a possibilidade de substituir uma representação mais detalhada de um sintagma nominal por uma nova variável e ``armazenar'' a representação completa deste sintagma nominal para uso posterior. Ao fim, as representações podem ser ``resgatadas'' do armazenamento, em qualquer ordem. Ao se ``resgatar'' uma representação após alguma outra, o quantificador do sintagma nominal resgatado posteriormente poderá ter escopo mais externo do que um quantificador da representação ``resgatada'' anteriormente. Desse modo, ao se possibilitar os ``resgates'' em ordens distintas, diferentes representações são formadas.

Agora, cada expressão (isto é, cada nó da árvore de análise sintática (\teng{parse})) é associada a uma $n$-upla chamada ``armazenamento''. O primeiro elemento do armazenamento será uma fórmula de cálculo lambda, bem como antes. É uma representação ``nuclear'' da expressão. Com efeito, chamaremos este elemento de \textit{núcleo} do armazenamento. Por sua vez, os outros elementos da $n$-upla serão pares $(\beta, i)$, em que $\beta$ é uma representação semântica para um sintagma nominal e $i$ é um indice para este sintagma. Estes pares são denominados \textit{operadores de ligação indexados} (\teng{indexed binding operators}).

Com mais detalhes, \textit{a priori} as representações não diferem muito de como eram. Os nós das folhas, não sendo nenhum um sintagma nominal quantificado, são análogos ao modo anterior, sendo armazenamentos com apenas uma entrada. Já um nó não-terminal pode ter sua representação montada de um modo ``usual'': ele tem como núcleo uma combinação dos núcleos de cada um de seus filhos na árvore; isto é, é a combinação dos núcleos dos armazenamentos dos termos que compõem a expressão mais complexa. Esta combinação é exatamente do mesmo modo como era feito até então. O restante do armazenamento do nó não-terminal é a justaposição (\teng{append}) do restante dos armazenamentos de cada um dos termos filhos. Em suma: quando a expressão é composta por outras na análise sintática, tudo ocorre de modo análogo a como ocorria na representação ``pura'' por cálculo lambda, preservando os operadores de ligação indexados de todas as sub-expressões que compõem a expressão maior.

Caso o nó não-terminal não seja um sintagma nominal quantificado, a represnetação ``usual'' é a sua única possível. Entretanto, o processo possui uma diferença quando o nó não-terminal é um sintagma nominal quantificado. Além da composição ``usual'' para outros nós, há uma segunda representação possível. Isso merece ser destacado:

\begin{oframed}\textbf{Armazenagem (Cooper)}\\
Seja o armazenamento $\langle\phi, (\beta, j), \dots, (\beta', k)\rangle$ a representação semântica ``usual'' para um sintagma nominal quantificado. O armazenamento $\langle\lambda u.(u@z_i), (\phi, i), (\beta, j), \dots, (\beta', k)\rangle $, onde $i$ é um índice único\footnotemark também é uma representação para este sintagma nominal quantificado.
\end{oframed}
\footnotetext{{isto é, não utilizado até então}}

Isto significa que sintagmas nominais quantificados podem ter suas representações montadas de dois modos. Neste ponto, nosso algoritmo terá uma escolha de aplicar ou não a regra de armazenagem. Ao se desejar saber a representação de uma frase em específico, esperaremos que nosso sistema nos retorne todas as representações possíveis. Perceba também que a regra não é recursiva. Há apenas duas opções: manter a representação ``usual'' ou realizar a operação de armazenagem.

Após todo este processo, teremos uma frase cuja representação é um armazenamento. É necessário lidar com isto de algum modo, pois o que desejamos é que uma frase possa ser representada por expressões de lógica de primeira ordem, não por um armazenamento. Aqui é que poderemos ``resgatar'' nossos operadores de ligação indexado, que foram previamente armazenados. Para isso, usaremos a seguinte regra de resgate:

\begin{oframed} \textbf{Resgate (Cooper)}\\
Sejam $\sigma_1$ e $\sigma_2$ duas seqüências (possivelmente vazias) de operadores de ligação. Se o armazenamento $\langle\phi, \sigma_1, (\beta, i), \sigma_2\rangle$ a uma frase (\teng{sentence}), então o armazenamento $\langle\beta @ \lambda z_i . \phi , \sigma_1, \sigma_2 \rangle$ também é associado a esta frase.
\end{oframed}

Um armazenamento composto apenas por um núcleo, após sucessivas aplicações da regra de resgate, será uma fórmula bem formada de primeira ordem, como desejávamos.

Para visualizarmos este processo, vamos para um exemplo:

%\begin{center}
\Tree [.{\teng{Every man loves a woman} (\teng{Sentence}) } 
[.{\teng{Every man} (\teng{NP})} {\teng{Every} (\teng{Determiner})} {\teng{man} (\teng{Noun})} ]
[.{\teng{loves a woman} (\teng{VP})}
{\teng{loves} (\teng{TV})} [.{\teng{a woman} (\teng{NP})} {\teng{a} (\teng{Determiner})} {\teng{woman} (\teng{Noun})} ] ]
] \\ 
%\end{center}

Esta é a árvore de análise sintática. Construindo os significados a partir das folhas e subindo, uma das possíveis árvores que podemos alcançar é:
\todo[inline]{converter essas árvores para tikz, para poder aumentar a fonte}
\scriptsize
%\footnotesize
\Tree [.{\teng{Every man loves a woman} (\teng{Sentence}) \\ $\langle love(z_1,z_2), $\\$ (\lambda q. \forall x(man(x) \rightarrow q@x), 1),$\\$ (\lambda q. \exists x(woman(x) \land q@x),2) \rangle$ } 
[.{\teng{Every man} (\teng{NP}) \\$\langle \lambda u . u@z_1 ,$\\$ (\lambda q. \forall x(man(x) \rightarrow q@x), 1) \rangle$} {\teng{Every} (\teng{Determiner}) \\ $\langle \lambda p . \lambda q. \forall x(p@x \rightarrow q@x) \rangle$} {\teng{man} (\teng{Noun}) \\ $\langle \lambda x. man(x) \rangle$} ]
[.{\teng{loves a woman} (\teng{VP}) \\ $\langle \lambda x. love(x,z_2),$\\$ (\lambda q. \exists x(woman(x) \land q@x),2) \rangle$}
{\teng{loves} (\teng{TV}) \\ $\langle \lambda k. \lambda x. k @ (\lambda y. love(x,y)) \rangle$} [.{\teng{a woman} (\teng{NP}) \\ $\langle \lambda u. u@z_2 ,$\\$ (\lambda q. \exists x(woman(x) \land q@x),2) \rangle$} {\teng{a} (\teng{Determiner}) \\ $\langle \lambda p. \lambda q. \exists x (p@x \land q@x) \rangle$} {\teng{woman} (\teng{Noun}) \\ $\langle \lambda x. woman(x) \rangle$} ] ]
]
\normalsize

Agora, o que resta é converter o armazenamento representativo da frase completa nas possíveis fórmulas de primeira ordem através da operação de resgate. 

\begin{align*}
 \text{Inicialmente:} \\
 \langle love(z_1,z_2),& \\ &(\lambda q. \forall x(man(x) \rightarrow q@x), 1),  (\lambda q. \exists x(woman(x) \land q@x),2) \rangle \\
 \text{Resgatando o operador de ligação 1:}  \\
 \langle \lambda q. \forall x(man(x) \rightarrow q@x) &@ (\lambda z_1 . love(z_1,z_2)),  \\&(\lambda q. \exists x(woman(x) \land q@x),2)\rangle \\
 \beta\text{-convertendo:} \\
 \langle \forall x (man(x) \rightarrow love(x,z_2)), &\\&(\lambda q. \exists x(woman(x) \land q@x),2)\rangle \\
 \text{Resgatando o operador de ligação 2:} \\
 \langle (\lambda q. \exists x(woman(x) \land q@x))@&(\forall x (man(x) \rightarrow love(x,z_2))) \rangle  \\
 \alpha\text{-convertendo e }  \beta\text{-convertendo:} \\
 \langle \exists x (woman(x) \land \forall y(man(y) &\rightarrow love(y,x))) \rangle  \\
\end{align*}

Assim, chegamos a uma das duas interpretações: a de que todos os homens amam uma mesma mulher. Se resgatarmos o operador de ligação 2 e só depois resgatarmos o operador de ligação 1, teremos a outra leitura: $\forall y(man(y) \rightarrow \exists x (woman (x) \land love(y,x)))$

Portanto, desenvolvemos um método sistemático que pode capturar as ambigüidades de escopo, produzindo as leituras possíveis. O que nos resta agora é a pergunta: será que nosso método é de fato capaz de capturar todas as ambigüidades de escopo? Infelizmente, deve estar claro que não. Iremos apontar duas frases nas quais o método não é suficiente.

\subsubsection{Dificuldades}

A primeira frase é: \expreng{Every man doesn't love a woman}. A presença da negação traz elementos interessantes. Em primeiro lugar, ela em si é uma fonte possível de ambigüidades de escopo. Entretanto, o método de armazenamento de Cooper não tratou a negação de nenhum modo especial. Além disso, esse exemplo mostra o interesse em manter a operação de armazenamento como opcional. Esta frase pode ser interpretado de seis modos:
\begin{enumerate}
\item $\neg \forall x (man(x) \rightarrow \exists y (woman(y) \land love(x,y))) $
\item $\neg \exists y(woman(y) \land \forall x(man(x) \rightarrow love(x,y)))$
\item $\forall x (man(x) \rightarrow \neg \exists y (woman(y) \land love(x,y)))$
\item $\exists y(woman(y) \land \neg \forall x(man(x) \rightarrow love(x,y)))$
\item $\forall x (man(x) \rightarrow \exists y (woman(y) \land \neg love(x,y)))$
\item $\exists y(woman(y) \land \forall x(man(x) \rightarrow \neg love(x,y)))$
\end{enumerate}

Apesar disso, nosso método apenas gerará três desses modos: 3, 5 e 6. Assim, a presença da negação de fato afeta a capacidade de nosso sistema produzir todas as interpretações.

Por sua vez, a segunda frase é: \expreng{Every criminal with a gun is dangerous.} Aplicando nosso método, teremos os seguintes resultados:
\begin{enumerate}
\item $\forall x((criminal(x) \land \exists y (gun(y) \land with(x,y))) \rightarrow smoke(x))$
\item $\exists y(gun(y) \land \forall x(criminal(x) \land with(x,y) \rightarrow smoke(x)))$
\item $\forall x((criminal(x) \land with(x,y)) \rightarrow \exists z(gun(z) \land smoke(x))) $
\end{enumerate}

Apesar dos resultados 1 e 2 serem perfeitamente razoáveis, sendo as interpretações que desejávamos, a interpretação 3 possui uma variável livre, não sendo uma sentença de primeira ordem. Isso nos mostra que há um problema com o nosso método. Como isso surgiu?

Realizando nosso procedimento e optando sempre por colocar a representação do sintagma nominal no armazenamento, montaremos a árvore: 
%(.......)

%Isto nos mostra o problema de sintagmas nominais aninhados ....

\subsection{Armazenamento de Keller}
Para lidar especificamente com o segundo problema do armazenamento de Cooper, Bill Keller propôs uma alteração: permitir armazenamentos aninhados. Assim, cada operador de ligação passa a ser composto não mais por uma fórmula de cálculo lambda e um índice único, mas sim por um armazenamento e um índice único. Isto altera a regra de armazenagem:

\begin{oframed}\textbf{Armazenagem (Keller)}\\
Sendo $\sigma$ uma seqüência (possivelmente vazia) de operadores de ligação, se o armazenamento $\langle\phi, \sigma\rangle$ é a representação semântica ``usual'' para um sintagma nominal quantificado, então o armazenamento $\langle\lambda u.(u@z_i), (\langle \phi, \sigma \rangle, i) \rangle $, onde $i$ é um índice único, também é uma representação para este sintagma nominal quantificado.
\end{oframed}

Por sua vez, também o resgate é alterado. Um operador de ligação só pode ser resgatado para aplicação do núcleo do armazenamento se todos os armazenamentos externos a ele já tiverem sido aplicados. Isto garante que, caso os sintagmas nominais estejam aninhados, então o sintagma nominal mais interno só terá seu operador resgatado após o resgate do sintagma nominal mais externo, evitando o tipo de problema que observamos. Portanto, nossa regra é:

\begin{oframed}\textbf{Resgate (Keller)}\\
Sejam $\sigma$, $\sigma_1$ e $\sigma_2$ seqüências (possivelmente vazias) de operadores de ligação. Se o armazenamento $\langle \phi, \sigma_1, ((\beta, \sigma), i), \sigma_2 \rangle$ é uma representação para uma frase (\teng{sentence}), então $\langle (\beta @ \lambda z_i . \phi ), \sigma_1, \sigma, \sigma_2 \rangle$ também o é.
\end{oframed}

Podemos então aplicar isto para o nosso exemplo:
%todo: árvore em tikz



\subsection{\textit{Hole Semantics}}